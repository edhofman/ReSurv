---
title: "A simple case study"
author: "Gabriele Pittarello"
date: "2023-10-05"
output: html_document
bibliography: references.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ReSurv)
library(data.table)
```


```{r}

beta=2*30
lambda=0.1 #1
k=1
b=1440
alpha=0.5
beta0 = 1.15129
beta1 = 1.95601

F_correct <- function(t, alpha, beta, lambda, k,b,beta_coef){
  #nu/xi*(t/xi)^(nu-1)
  #exp(-(t/xi)^nu)/(1-exp(-(t/xi)^nu)*
  #nu/xi*(t/xi)^(nu-1)*exp(beta1)
  exp(-beta^alpha *(lambda*exp(beta_coef)^(1/(alpha*k)) )^(alpha*k)*(t^(-alpha*k)-b^(-alpha*k)) )
}

c_correct_grouped<-c()
for (i in 0:(b-1)){
  t<-seq(i,i+1, by=0.001)
  n_t<-length(t)
  c_correct_grouped[i+1] <- sum(1-F_correct(t, alpha,beta,lambda,k,b, beta0) )/n_t
}
c_correct_grouped<-c(1,c_correct_grouped[1:(b-1)])

c_correct_grouped1<-c()
for (i in 0:(b-1)){
  t<-seq(i,i+1, by=0.001)
  n_t<-length(t)
  c_correct_grouped1[i+1] <- sum(1-F_correct(t, alpha,beta,lambda,k,b, beta1) )/n_t
}
c_correct_grouped1<-c(1,c_correct_grouped1[1:(b-1)])

plot_datac0 <- data.table(time=(b-1)-seq(0,(b-1),by=1)+1, true =1-c_correct_grouped)[order(time),]
plot_datac1 <- data.table(time=(b-1)-seq(0,(b-1),by=1)+1, true =1-c_correct_grouped1)[order(time),]


real_cty <- data.table(DP_rev_i=rep((b-1)-seq(0,(b-1),by=1)+1,2),
                       claim_type=rep(c("0","1"),each=b),
                       true =c(1-c_correct_grouped,1-c_correct_grouped1))


```



# Introduction

In this vignette we want to generate a data set from scenario Alpha described in @hiabu23 and using COX to fit and predict future IBNR. Below, we describe the data set covariates.

| Covariates                                       | Description        |
|--------------------------------------------------|--------------------|
| `claim_number`                                   | Policy identifier. |
| `claim_type` $\in  \left\{0, 1 \right\}$         | Type of claim.     |
| `AM`                                             | Accident month.    |
| `RM`                                             | Reporting month.   |
| `DM`                                             | Development month. |


The data are simulated on a daily grid, over a four years time horizon with a daily exposure of $200$ claims.

```{r eval=FALSE, include=TRUE}
# Input data

input_data0 <- data_generator(random_seed = 1964,
                              scenario=0,
                              time_unit = 1/360,
                              years = 4,
                              yearly_exposure = 200)

```

In the pre-processing of the data, we specify `claim_type`, as a categorical feature and `AP` as a continuous feature. The calendar period of reporting is `RP`. The input data granularity is `"days"` and we want quarterly predictions (we set `output_time_granularity` to `"quarters"`. The time horizon is $4$ years.

```{r eval=FALSE, include=TRUE}
individual_data <- IndividualData(data = input_data0,
                                  categorical_features = c("claim_type"),
                                  continuous_features = "AP",
                                  accident_period="AP",
                                  calendar_period="RP",
                                  input_time_granularity = "days",
                                  output_time_granularity = "quarters",
                                  years=4)
```

```{r eval=FALSE, include=TRUE}
resurv.fit.cox <- ReSurv(individual_data,
                         hazard_model = "cox")
```

## Model the survival function (COX model)

```{r}

hazard_frame_updatedCX <- resurv.fit.cox$hazard_frame

dt_totCX <- merge(hazard_frame_updatedCX,
                real_cty,
                all=T)

```
```{r}
tmp <- dt_totCX %>%
  filter(claim_type==1, AP_i==5) %>%
  select(S_i,true,DP_rev_i,claim_type)

tmp<- tmp %>% pivot_longer(cols=c('S_i','true'),
                     names_to = c('curve'),
                     values_to = c('SF'))




```

```{r}
ggplot(tmp, aes(x=DP_rev_i,
                y=SF,
                color=curve))+
  geom_line()
```



# eXtreme Gradient Boosting

```{r}
hp_scenario_alpha_xgb <- list(params=list(booster="gbtree",
                                          eta=0.9887265,
                                          subsample=0.7924135 ,
                                          alpha=10.85342,
                                          lambda=6.213317,
                                          min_child_weight=3.042204,
                                          max_depth = 1),
                                          print_every_n = 0,
                                          nrounds=3000,
                                          verbose=F,
                                          early_stopping_rounds = 500)

```


```{r}
resurv.model.xgb.A <-  ReSurv(individual_data,
                              hazard_model = "xgboost",
                              hparameters=hp_scenario_alpha_xgb)
```



```{r}

hazard_frame_updatedXGB <- resurv.model.xgb.A$hazard_frame

dt_tot <- merge(hazard_frame_updatedXGB,
                real_cty,
                all=T)

```

```{r}
tmp <- dt_tot %>%
  filter(claim_type==1, AP_i==13) %>%
  select(S_i,true,DP_rev_i,claim_type)

tmp<- tmp %>% pivot_longer(cols=c('S_i','true'),
                     names_to = c('curve'),
                     values_to = c('SF'))




```
```{r}
dt_tot
```

```{r}
ggplot(tmp, aes(x=DP_rev_i,
                y=SF,
                color=curve))+
  geom_line()
```

# Compute error measures

In this section we show how to compute the performance measures that we suggest in the manuscript to evaluate our models.

Below we elaborate the data to evaluate our performances yearly.

```{r}
input_data2 <- data_generator(random_seed = 1,
                              scenario=0,
                              time_unit = 1/360,
                              years = 4,
                              yearly_exposure = 200)

individual_data2 <- IndividualData(input_data2,
                                  id="claim_number",
                                  continuous_features="AP_i",
                                  categorical_features="claim_type",
                                  accident_period="AP",
                                  calendar_period="RP",
                                  input_time_granularity = "days",
                                  output_time_granularity = "years",
                                  years=4,
                                  continuous_features_spline=NULL,
                                  calendar_period_extrapolation=F)
```


## COX

```{r}

conversion_factor <- individual_data$conversion_factor


resurv.predict <- resurv.fit.predict <- predict(resurv.fit.cox,
                    grouping_method = "probability")

max_dp_i <-1440

    
crps_dt <- ReSurv::survival_crps(resurv.predict$ReSurvFit)
crps_result <- mean(crps_dt$crps)

```

```{r}
crps_result
```
### ARE total

```{r}
true_output <- resurv.predict$ReSurvFit$IndividualData$full.data %>%
    mutate(
      DP_rev_o = floor(max_dp_i*conversion_factor)-ceiling(DP_i*conversion_factor+((AP_i-1)%%(1/conversion_factor))*conversion_factor) +1,
      AP_o = ceiling(AP_i*conversion_factor),
      TR_o= AP_o-1
    ) %>%
    filter(DP_rev_o <=TR_o) %>%
    group_by(claim_type, AP_o, DP_rev_o) %>%
    mutate(claim_type = as.character(claim_type)) %>%
    summarize(I=sum(I), .groups = "drop") %>%
    filter(DP_rev_o>0) #we cant have =0, because corresponds to half a parallelogram.

  #Total output
  score_total<- resurv.predict$hazard_frame_output[,c("claim_type","AP_o", "DP_rev_o", "I_expected")] %>%
    inner_join(true_output, by =c("claim_type","AP_o", "DP_rev_o")) %>%
    mutate(ave = I-I_expected,
           abs_ave = abs(ave)) %>%
    # from here it is reformulated for the are tot
    ungroup()%>%
    group_by(AP_o, DP_rev_o) %>%
    reframe(abs_ave=abs(sum(ave)),
           I=sum(I))
    
are_tot=sum(score_total$abs_ave)/sum(score_total$I)
```


```{r}

are_tot
```


### ARE calendar quarters

```{r}
  dfs_output <- resurv.predict$hazard_frame_output %>%
    select(AP_o, claim_type, DP_rev_o, df_o) %>%
    mutate(DP_rev_o = DP_rev_o) %>% 
    distinct()

  #Cashflow on output scale.Etc quarterly cashflow development
  score_diagonal <- resurv.predict$ReSurvFit$IndividualData$full.data  %>%
    mutate(
      DP_rev_o = floor(max_dp_i*conversion_factor)-ceiling(DP_i*conversion_factor+((AP_i-1)%%(1/conversion_factor))*conversion_factor) +1,
      AP_o = ceiling(AP_i*conversion_factor)
    ) %>%
    group_by(claim_type, AP_o, DP_rev_o) %>%
    mutate(claim_type = as.character(claim_type)) %>%
    summarize(I=sum(I), .groups = "drop") %>%
    group_by(claim_type, AP_o) %>%
    arrange(desc(DP_rev_o)) %>%
    mutate(I_cum=cumsum(I)) %>%
    mutate(I_cum_lag = lag(I_cum, default = 0)) %>%
    left_join(dfs_output, by = c("AP_o", "claim_type", "DP_rev_o")) %>%
    mutate(I_cum_hat =  I_cum_lag * df_o,
           RP_o = max(DP_rev_o)-DP_rev_o + AP_o) %>%
    inner_join(true_output[,c("AP_o", "DP_rev_o")] %>%  distinct()
               , by =c("AP_o", "DP_rev_o")) %>%
    group_by(AP_o,DP_rev_o) %>%
    reframe(abs_ave2_diag = abs(sum(I_cum_hat)-sum(I_cum)),
          I=sum(I)) 
    
    are_cal_q=sum(score_diagonal$abs_ave2_diag)/sum(score_diagonal$I)
```

```{r}
are_cal_q
```


### ARE calendar yearly

```{r}
resurv.predict <- predict(resurv.predict$ReSurvFit,
                                  newdata=individual_data2,
                             grouping_method = "probability")
    
    conversion_factor <- individual_data2$conversion_factor


  max_dp_i <-1440


  true_output <- individual_data2$full.data %>%
    mutate(
      DP_rev_o = floor(max_dp_i*conversion_factor)-ceiling(DP_i*conversion_factor+((AP_i-1)%%(1/conversion_factor))*conversion_factor) +1,
      AP_o = ceiling(AP_i*conversion_factor),
      TR_o= AP_o-1
    ) %>%
    filter(DP_rev_o <=TR_o) %>%
    group_by(claim_type, AP_o, DP_rev_o) %>%
    mutate(claim_type = as.character(claim_type)) %>%
    summarize(I=sum(I), .groups = "drop") %>%
    filter(DP_rev_o>0) #we cant have =0, because corresponds to half a parallelogram.

  dfs_output <- resurv.predict$hazard_frame_output %>%
    select(AP_o, claim_type, DP_rev_o, df_o) %>%
    mutate(DP_rev_o = DP_rev_o) %>% 
    distinct()

  #Cashflow on output scale.Etc quarterly cashflow development
  score_diagonal_yearly <- individual_data2$full.data  %>%
    mutate(
      DP_rev_o = floor(max_dp_i*conversion_factor)-ceiling(DP_i*conversion_factor+((AP_i-1)%%(1/conversion_factor))*conversion_factor) +1,
      AP_o = ceiling(AP_i*conversion_factor)
    ) %>%
    group_by(claim_type, AP_o, DP_rev_o) %>%
    mutate(claim_type = as.character(claim_type)) %>%
    summarize(I=sum(I), .groups = "drop") %>%
    group_by(claim_type, AP_o) %>%
    arrange(desc(DP_rev_o)) %>%
    mutate(I_cum=cumsum(I)) %>%
    mutate(I_cum_lag = lag(I_cum, default = 0)) %>%
    left_join(dfs_output, by = c("AP_o", "claim_type", "DP_rev_o")) %>%
    mutate(I_cum_hat =  I_cum_lag * df_o,
           RP_o = max(DP_rev_o)-DP_rev_o + AP_o) %>%
    inner_join(true_output[,c("AP_o", "DP_rev_o")] %>%  distinct()
               , by =c("AP_o", "DP_rev_o")) %>%
    group_by(AP_o,DP_rev_o) %>%
    reframe(abs_ave2_diag = abs(sum(I_cum_hat)-sum(I_cum)),
          I=sum(I)) 
    
    are_cal_y=sum(score_diagonal_yearly$abs_ave2_diag)/sum(score_diagonal_yearly$I)
    
```

```{r}
are_cal_y
```







